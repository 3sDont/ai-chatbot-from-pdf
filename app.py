# app.py

import streamlit as st
import os
import sys
import base64 # ThÆ° viá»‡n cáº§n thiáº¿t Ä‘á»ƒ hiá»ƒn thá»‹ PDF

# --- ThÃªm thÆ° má»¥c gá»‘c vÃ o sys.path ---
project_root = os.path.dirname(os.path.abspath(__file__))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# --- Import tá»« kiáº¿n trÃºc má»›i ---
from src.components.data_loader import DataLoader
from src.components.chunker import Chunker
from src.components.embedder import Embedder
from src.components.vector_store import VectorStore
from src.pipelines.llm_models import GroqLLM
from src.pipelines.rag_pipeline import RAGPipeline

# --- Cáº¥u hÃ¬nh trang ---
st.set_page_config(page_title="ğŸ“š AI Chatbot Pro", layout="wide", initial_sidebar_state="expanded")

# --- HÃ€M TIá»†N ÃCH Äá»‚ HIá»‚N THá»Š PDF ---
def display_pdf(file):
    """
    Hiá»ƒn thá»‹ má»™t file PDF trong Streamlit báº±ng cÃ¡ch nhÃºng nÃ³ vÃ o tháº» <embed>.
    PhÆ°Æ¡ng phÃ¡p nÃ y tÆ°Æ¡ng thÃ­ch tá»‘t hÆ¡n vá»›i chÃ­nh sÃ¡ch báº£o máº­t cá»§a trÃ¬nh duyá»‡t.
    """
    # Äá»c file
    file.seek(0)
    base64_pdf = base64.b64encode(file.read()).decode('utf-8')
    
    # Táº¡o HTML Ä‘á»ƒ nhÃºng PDF báº±ng tháº» <embed>
    pdf_display = f'<embed src="data:application/pdf;base64,{base64_pdf}" width="100%" height="800" type="application/pdf">'
    
    # Hiá»ƒn thá»‹ HTML
    st.markdown(pdf_display, unsafe_allow_html=True)

# --- KHá»I Táº O CÃC Äá»I TÆ¯á»¢NG (DÃ™NG CACHE) ---
@st.cache_resource
def initialize_models():
    try:
        embedder = Embedder()
        llm = GroqLLM()
        return embedder, llm
    except ValueError as e:
        st.error(f"Lá»—i khá»Ÿi táº¡o: {e}. Vui lÃ²ng kiá»ƒm tra API key trong Streamlit Secrets.")
        return None, None

def initialize_rag_pipeline(embedder, llm):
    return RAGPipeline(Chunker(), embedder, VectorStore(), llm)

# Táº£i model vÃ  kiá»ƒm tra lá»—i
embedder_model, llm_model = initialize_models()
if not (embedder_model and llm_model):
    st.stop()

# Khá»Ÿi táº¡o pipeline vÃ  cÃ¡c biáº¿n session state
if 'rag_pipeline' not in st.session_state:
    st.session_state.rag_pipeline = initialize_rag_pipeline(embedder_model, llm_model)
if 'messages' not in st.session_state:
    st.session_state.messages = []
if 'document_processed' not in st.session_state:
    st.session_state.document_processed = False
if 'uploaded_file' not in st.session_state:
    st.session_state.uploaded_file = None

# --- GIAO DIá»†N SIDEBAR Äá»‚ UPLOAD ---
with st.sidebar:
    st.header("âš™ï¸ Báº£ng Äiá»u Khiá»ƒn")
    uploaded_file = st.file_uploader("Táº£i lÃªn tÃ i liá»‡u PDF cá»§a báº¡n", type=["pdf"])

    if uploaded_file:
        # Xá»­ lÃ½ chá»‰ khi cÃ³ file má»›i Ä‘Æ°á»£c táº£i lÃªn
        if st.session_state.uploaded_file is None or st.session_state.uploaded_file.name != uploaded_file.name:
            st.session_state.uploaded_file = uploaded_file
            st.session_state.document_processed = False
            st.session_state.messages = [] # Reset chat khi cÃ³ file má»›i

            with st.status("âš™ï¸ Äang xá»­ lÃ½ tÃ i liá»‡u...", expanded=True) as status:
                status.write("Äang Ä‘á»c file...")
                loader = DataLoader()
                # Chá»‰ dÃ¹ng luá»“ng xá»­ lÃ½ PDF nhanh cho giao diá»‡n tÆ°Æ¡ng tÃ¡c nÃ y
                content = loader.load_from_upload(uploaded_file)
                
                if content:
                    status.write("Äang phÃ¢n tÃ­ch vÃ  ghi nhá»› ná»™i dung...")
                    st.session_state.rag_pipeline = initialize_rag_pipeline(embedder_model, llm_model)
                    st.session_state.rag_pipeline.setup_with_text(content)
                    st.session_state.document_processed = True
                    status.update(label="âœ… Xá»­ lÃ½ hoÃ n táº¥t!", state="complete", expanded=False)
                else:
                    status.update(label="Lá»—i Ä‘á»c file", state="error")
    
    st.markdown("---")
    st.markdown(
        "**LÆ°u Ã½:** Chá»©c nÄƒng xem trÆ°á»›c PDF vÃ  há»i Ä‘Ã¡p nhanh hoáº¡t Ä‘á»™ng tá»‘t nháº¥t vá»›i cÃ¡c file PDF cÃ³ text rÃµ rÃ ng."
    )

# --- Bá» Cá»¤C GIAO DIá»†N CHÃNH (2 Cá»˜T) ---
# TÃ¡ch biá»‡t hai cá»™t ngay tá»« Ä‘áº§u
col1, col2 = st.columns([5, 4]) # TÄƒng khÃ´ng gian cho PDF má»™t chÃºt

# Cá»™t 1: Hiá»ƒn thá»‹ PDF
with col1:
    st.subheader("ğŸ“„ Ná»™i dung tÃ i liá»‡u")
    if st.session_state.uploaded_file is not None:
        display_pdf(st.session_state.uploaded_file)
    else:
        st.info("Ná»™i dung tÃ i liá»‡u sáº½ Ä‘Æ°á»£c hiá»ƒn thá»‹ á»Ÿ Ä‘Ã¢y sau khi báº¡n táº£i lÃªn.")

# Cá»™t 2: Giao diá»‡n Chat
with col2:
    st.subheader("ğŸ¤– Chat vá»›i AI")
    
    if st.session_state.uploaded_file is None:
        st.info("Vui lÃ²ng táº£i lÃªn má»™t tÃ i liá»‡u Ä‘á»ƒ báº¯t Ä‘áº§u trÃ² chuyá»‡n.")
    else:
        if not st.session_state.document_processed:
            st.warning("Äang chá» xá»­ lÃ½ tÃ i liá»‡u...")
        else:
            st.success(f"ÄÃ£ sáºµn sÃ ng! Há»i Ä‘Ã¡p vá»: **{st.session_state.uploaded_file.name}**")

    # VÃ¹ng chá»©a tin nháº¯n
    chat_container = st.container(height=600) # Giá»›i háº¡n chiá»u cao Ä‘á»ƒ cuá»™n
    with chat_container:
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

    # Ã” nháº­p liá»‡u chat
    if prompt := st.chat_input("Äáº·t cÃ¢u há»i vá» tÃ i liá»‡u..."):
        if st.session_state.document_processed:
            st.session_state.messages.append({"role": "user", "content": prompt})
            with chat_container:
                with st.chat_message("user"):
                    st.markdown(prompt)

            with chat_container:
                with st.chat_message("assistant"):
                    with st.spinner("AI Ä‘ang suy nghÄ©..."):
                        response = st.session_state.rag_pipeline.query(prompt)
                        st.markdown(response)
            st.session_state.messages.append({"role": "assistant", "content": response})
        else:
            st.warning("Vui lÃ²ng táº£i lÃªn vÃ  chá» xá»­ lÃ½ tÃ i liá»‡u trÆ°á»›c.")
