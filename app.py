# app.py

import streamlit as st
from src.pdf_reader import PDFReader
from src.text_splitter import TextSplitter
from src.embedder import Embedder
from src.vector_store import VectorStore
from src.llm_model import LLMModel
from src.rag_chain import RAGChain
import os

# Cáº¥u hÃ¬nh giao diá»‡n Streamlit
st.set_page_config(page_title="ğŸ“˜ AI Chatbot tá»« PDF", layout="wide")
st.title("ğŸ“˜ AI Chatbot há»— trá»£ há»c táº­p")
st.markdown("Trá»£ lÃ½ áº£o cÃ³ kháº£ nÄƒng Ä‘á»c file PDF vÃ  tráº£ lá»i cÃ¢u há»i dá»±a trÃªn ná»™i dung tÃ i liá»‡u báº¡n cung cáº¥p.")

# Upload file
uploaded_file = st.file_uploader("ğŸ“ Táº£i lÃªn tÃ i liá»‡u PDF cá»§a báº¡n", type="pdf")

# Táº¡o cÃ¡c Ä‘á»‘i tÆ°á»£ng pipeline
pdf_reader = PDFReader()
text_splitter = TextSplitter(chunk_size=500, chunk_overlap=50)
embedder = Embedder()
vector_store = VectorStore()
llm = LLMModel()
rag_chain = RAGChain(embedder, vector_store, llm)

# Xá»­ lÃ½ khi cÃ³ file upload
if uploaded_file is not None:
    with st.spinner("ğŸ“– Äang Ä‘á»c vÃ  xá»­ lÃ½ tÃ i liá»‡u..."):
        text = pdf_reader.read(uploaded_file)
        chunks = text_splitter.split(text)
        embeddings = embedder.embed_documents(chunks)
        vector_store.add_embeddings(embeddings, chunks)
        vector_store.save()  # lÆ°u vÃ o embedding_store.pkl

    st.success("âœ… TÃ i liá»‡u Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½ xong! Báº¡n cÃ³ thá»ƒ báº¯t Ä‘áº§u Ä‘áº·t cÃ¢u há»i.")

    # Khung há»i Ä‘Ã¡p
    query = st.text_input("ğŸ’¬ Nháº­p cÃ¢u há»i cá»§a báº¡n vá» tÃ i liá»‡u:")

    if query:
        with st.spinner("ğŸ¤– Äang táº¡o cÃ¢u tráº£ lá»i..."):
            answer = rag_chain.query(query)
        st.markdown(f"**ğŸ“Œ Tráº£ lá»i:** {answer}")
