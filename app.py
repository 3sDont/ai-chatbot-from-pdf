# app.py

import streamlit as st
from src.pdf_loader import PDFLoader
from src.embedder import Embedder
from src.vector_store import VectorStore
from src.llm_model import LLMModel
from src.rag_chain import RAGPipeline
import tempfile

st.set_page_config(page_title="AI Chatbot há»c tá»« PDF", layout="centered")
st.title("ğŸ“š AI Chatbot há»— trá»£ há»c táº­p tá»« giÃ¡o trÃ¬nh PDF")

# --- Táº£i file PDF tá»« ngÆ°á»i dÃ¹ng ---
uploaded_file = st.file_uploader("ğŸ“„ Táº£i lÃªn file giÃ¡o trÃ¬nh (.pdf)", type=["pdf"])

if uploaded_file:
    with st.spinner("ğŸ” Äang xá»­ lÃ½ file PDF..."):
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
            tmp_file.write(uploaded_file.read())
            pdf_path = tmp_file.name

        # 1. TÃ¡ch vÄƒn báº£n
        loader = PDFLoader(pdf_path)
        chunks = loader.split_pdf()

        # 2. MÃ£ hÃ³a & lÆ°u vector
        embedder = Embedder()
        vectors = embedder.encode(chunks)
        vector_store = VectorStore()
        vector_store.add_documents(chunks, vectors)

        # 3. Load LLM
        llm = LLMModel()
        rag = RAGPipeline(embedder, vector_store, llm)

        st.success("âœ… File Ä‘Ã£ xá»­ lÃ½ xong! Báº¡n cÃ³ thá»ƒ Ä‘áº·t cÃ¢u há»i.")

        # --- Chat interface ---
        question = st.text_input("ğŸ’¬ CÃ¢u há»i cá»§a báº¡n:")
        if question:
            with st.spinner("ğŸ¤– Äang suy nghÄ©..."):
                answer = rag.ask(question)
                st.markdown("### âœ… Tráº£ lá»i:")
                st.markdown(answer)
